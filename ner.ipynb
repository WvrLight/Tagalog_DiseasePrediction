{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from math import nan\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/ner.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.n_sent = 1\n",
    "        self.dataset = dataset\n",
    "        self.empty = False\n",
    "        def agg_func(s): return [(w, t) for w, t in zip(s[\"word\"].values.tolist(),\n",
    "                                                        s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "\n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mayroon', 'O'), ('ding', 'O'), ('pagsikip', 'B-SYMPTOM'), ('sa', 'I-SYMPTOM'), ('aking', 'O'), ('dibdib', 'I-SYMPTOM'), ('at', 'O'), ('nakakaranas', 'O'), ('din', 'O'), ('ng', 'O'), ('pag-ubo', 'B-SYMPTOM'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "sentences = getter.sentences\n",
    "\n",
    "print(sentences[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 19\n"
     ]
    }
   ],
   "source": [
    "maxlen = max([len(s) for s in sentences])\n",
    "print('Maximum sequence length:', maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-SYMPTOM', 'I', 'B-SYMPTOM', 'O']\n"
     ]
    }
   ],
   "source": [
    "tags = []\n",
    "for tag in set(dataset[\"tag\"].values):\n",
    "    if tag is nan or isinstance(tag, float):\n",
    "        tags.append('UNKNOWN')\n",
    "    else:\n",
    "        tags.append(tag)\n",
    "print(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tags = len(tags)\n",
    "n_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(dataset[\"word\"].values))\n",
    "words.append(\"END\")\n",
    "words.append(\"UNKNOWN\")\n",
    "\n",
    "n_words = len(words)\n",
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from future.utils import iteritems\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "idx2tag = {v: k for k, v in iteritems(tag2idx)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "ner_config = {\n",
    "    \"n_tags\": n_tags,\n",
    "    \"n_words\": n_words,\n",
    "    \"maxlen\": maxlen\n",
    "}\n",
    "\n",
    "folder_name = 'cfg'\n",
    "\n",
    "with open(\"{}/{}.json\".format(folder_name, \"word_list\"), \"w\") as file_path:\n",
    "    json.dump(word2idx, file_path)\n",
    "\n",
    "with open(\"{}/{}.json\".format(folder_name, \"ner_config\"), \"w\") as file_path:\n",
    "    json.dump(ner_config, file_path)\n",
    "\n",
    "with open(\"{}/{}.json\".format(folder_name, \"tags\"), \"w\") as file_path:\n",
    "    json.dump(tags, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.data_utils import pad_sequences\n",
    "x = [[word2idx[w[0]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pad_sequences(maxlen=maxlen, sequences=x, padding=\"post\", value=n_words - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_idx = [[tag2idx[w[1]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pad_sequences(maxlen=maxlen, sequences=y_idx, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, GRU, Embedding, Dense, TimeDistributed, Bidirectional, Activation\n",
    "from tensorflow.keras import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "#y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "#x_test = tf.convert_to_tensor(x_test, dtype=tf.float32)\n",
    "#y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.layers.crf import CRF\n",
    "#from keras_crf import CRFModel\n",
    "\n",
    "MODEL_TYPE = 'GRU'\n",
    "\n",
    "word_embedding_size = 300\n",
    "\n",
    "input = tf.keras.layers.Input(shape=(None,), dtype=tf.int32)\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=n_words,\n",
    "                    output_dim=word_embedding_size, input_length=maxlen))\n",
    "\n",
    "if (MODEL_TYPE == 'LSTM'):\n",
    "    model.add(Bidirectional(LSTM(units=word_embedding_size,\n",
    "            return_sequences=True,\n",
    "            dropout=0.5,\n",
    "            recurrent_dropout=0.5,\n",
    "            kernel_initializer=tf.keras.initializers.he_normal())))\n",
    "    model.add(LSTM(units=word_embedding_size * 2,\n",
    "            return_sequences=True,\n",
    "            dropout=0.5,\n",
    "            recurrent_dropout=0.5,\n",
    "            kernel_initializer=tf.keras.initializers.he_normal()))\n",
    "else:\n",
    "    model.add(Bidirectional(GRU(units=word_embedding_size,\n",
    "            return_sequences=True,\n",
    "            dropout=0.5,\n",
    "            recurrent_dropout=0.5,\n",
    "            kernel_initializer=tf.keras.initializers.he_normal())))\n",
    "    model.add(GRU(units=word_embedding_size * 2,\n",
    "            return_sequences=True,\n",
    "            dropout=0.5,\n",
    "            recurrent_dropout=0.5,\n",
    "            kernel_initializer=tf.keras.initializers.he_normal()))\n",
    "model.add(TimeDistributed(Dense(n_tags)))\n",
    "model.add(Activation('softmax'))\n",
    "#crf = CRF(n_tags + 1)\n",
    "#model.add(crf)\n",
    "# embedding = Embedding(input_dim=n_words,\n",
    "#                   output_dim=word_embedding_size, input_length=maxlen)(input)\n",
    "# bi_lstm = Bidirectional(LSTM(units=word_embedding_size,\n",
    "#                            return_sequences=True,\n",
    "#                            dropout=0.5,\n",
    "#                            recurrent_dropout=0.5,\n",
    "#                              kernel_initializer=tf.keras.initializers.he_normal()))(embedding)\n",
    "# lstm = LSTM(units=word_embedding_size * 2,\n",
    "#                             return_sequences=True,\n",
    "#                             dropout=0.5,\n",
    "#                             recurrent_dropout=0.5,\n",
    "#                             kernel_initializer=tf.keras.initializers.he_normal())(bi_lstm)\n",
    "# kernel = TimeDistributed(Dense(n_tags, activation=\"relu\"))(lstm)\n",
    "# crf = CRF(n_tags + 1)\n",
    "\n",
    "#outputs = crf(kernel)\n",
    "\n",
    "# model = Model(inputs=input, outputs=kernel)\n",
    "# model.add_loss(tf.abs(tf.reduce_mean(kernel)))\n",
    "\n",
    "#base = Model(inputs=input, outputs=kernel)\n",
    "#model = CRFModel(base, n_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(\n",
    "    optimizer=adam,\n",
    "    metrics=['acc'],\n",
    "    loss=\"categorical_crossentropy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 19, 300)           57000     \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 19, 600)          1083600   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 19, 600)           2163600   \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 19, 4)            2404      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 19, 4)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,306,604\n",
      "Trainable params: 3,306,604\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the best only\n",
    "if (MODEL_TYPE == 'LSTM'):\n",
    "    filepath = \"bilstm.h5\"\n",
    "else:\n",
    "    filepath = \"bigru.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3850 - acc: 0.2409\n",
      "Epoch 1: val_acc improved from -inf to 0.80702, saving model to bigru.h5\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.3850 - acc: 0.2409 - val_loss: 1.0906 - val_acc: 0.8070\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0772 - acc: 0.7186\n",
      "Epoch 2: val_acc improved from 0.80702 to 0.84211, saving model to bigru.h5\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 1.0772 - acc: 0.7186 - val_loss: 0.8711 - val_acc: 0.8421\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8439 - acc: 0.7348\n",
      "Epoch 3: val_acc did not improve from 0.84211\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 0.8439 - acc: 0.7348 - val_loss: 0.7213 - val_acc: 0.8421\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7015 - acc: 0.7308\n",
      "Epoch 4: val_acc did not improve from 0.84211\n",
      "1/1 [==============================] - 1s 707ms/step - loss: 0.7015 - acc: 0.7308 - val_loss: 0.6270 - val_acc: 0.8421\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6145 - acc: 0.7490\n",
      "Epoch 5: val_acc did not improve from 0.84211\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 0.6145 - acc: 0.7490 - val_loss: 0.5672 - val_acc: 0.8421\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5789 - acc: 0.7530\n",
      "Epoch 6: val_acc did not improve from 0.84211\n",
      "1/1 [==============================] - 1s 713ms/step - loss: 0.5789 - acc: 0.7530 - val_loss: 0.5302 - val_acc: 0.8421\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5688 - acc: 0.7510\n",
      "Epoch 7: val_acc did not improve from 0.84211\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 0.5688 - acc: 0.7510 - val_loss: 0.5113 - val_acc: 0.8421\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5686 - acc: 0.7470\n",
      "Epoch 8: val_acc did not improve from 0.84211\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.5686 - acc: 0.7470 - val_loss: 0.5019 - val_acc: 0.8421\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5640 - acc: 0.7530\n",
      "Epoch 9: val_acc did not improve from 0.84211\n",
      "1/1 [==============================] - 1s 747ms/step - loss: 0.5640 - acc: 0.7530 - val_loss: 0.4966 - val_acc: 0.8421\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5435 - acc: 0.7611\n",
      "Epoch 10: val_acc did not improve from 0.84211\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.5435 - acc: 0.7611 - val_loss: 0.4963 - val_acc: 0.8421\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5112 - acc: 0.7713\n",
      "Epoch 11: val_acc did not improve from 0.84211\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 0.5112 - acc: 0.7713 - val_loss: 0.5036 - val_acc: 0.8246\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4972 - acc: 0.7854\n",
      "Epoch 12: val_acc did not improve from 0.84211\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 0.4972 - acc: 0.7854 - val_loss: 0.5186 - val_acc: 0.8421\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4869 - acc: 0.8117\n",
      "Epoch 13: val_acc did not improve from 0.84211\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.4869 - acc: 0.8117 - val_loss: 0.5336 - val_acc: 0.8070\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4863 - acc: 0.7976\n",
      "Epoch 14: val_acc did not improve from 0.84211\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 0.4863 - acc: 0.7976 - val_loss: 0.5381 - val_acc: 0.7544\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4839 - acc: 0.7996\n",
      "Epoch 15: val_acc did not improve from 0.84211\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 0.4839 - acc: 0.7996 - val_loss: 0.5287 - val_acc: 0.7719\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4741 - acc: 0.7996\n",
      "Epoch 16: val_acc did not improve from 0.84211\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.4741 - acc: 0.7996 - val_loss: 0.5083 - val_acc: 0.8246\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4546 - acc: 0.8057\n",
      "Epoch 17: val_acc did not improve from 0.84211\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 0.4546 - acc: 0.8057 - val_loss: 0.4849 - val_acc: 0.8246\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4361 - acc: 0.8219\n",
      "Epoch 18: val_acc did not improve from 0.84211\n",
      "1/1 [==============================] - 1s 712ms/step - loss: 0.4361 - acc: 0.8219 - val_loss: 0.4665 - val_acc: 0.8421\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4295 - acc: 0.8300\n",
      "Epoch 19: val_acc improved from 0.84211 to 0.85965, saving model to bigru.h5\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.4295 - acc: 0.8300 - val_loss: 0.4562 - val_acc: 0.8596\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4261 - acc: 0.8219\n",
      "Epoch 20: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.4261 - acc: 0.8219 - val_loss: 0.4528 - val_acc: 0.8421\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4189 - acc: 0.8158\n",
      "Epoch 21: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.4189 - acc: 0.8158 - val_loss: 0.4525 - val_acc: 0.8596\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4248 - acc: 0.8077\n",
      "Epoch 22: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.4248 - acc: 0.8077 - val_loss: 0.4581 - val_acc: 0.8421\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3997 - acc: 0.8300\n",
      "Epoch 23: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 0.3997 - acc: 0.8300 - val_loss: 0.4732 - val_acc: 0.8070\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3868 - acc: 0.8401\n",
      "Epoch 24: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.3868 - acc: 0.8401 - val_loss: 0.4933 - val_acc: 0.7719\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3920 - acc: 0.8300\n",
      "Epoch 25: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.3920 - acc: 0.8300 - val_loss: 0.5044 - val_acc: 0.7719\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3853 - acc: 0.8421\n",
      "Epoch 26: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.3853 - acc: 0.8421 - val_loss: 0.5028 - val_acc: 0.7719\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3821 - acc: 0.8401\n",
      "Epoch 27: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 722ms/step - loss: 0.3821 - acc: 0.8401 - val_loss: 0.4894 - val_acc: 0.7719\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3573 - acc: 0.8482\n",
      "Epoch 28: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 0.3573 - acc: 0.8482 - val_loss: 0.4739 - val_acc: 0.7895\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3407 - acc: 0.8684\n",
      "Epoch 29: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 0.3407 - acc: 0.8684 - val_loss: 0.4635 - val_acc: 0.8246\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3457 - acc: 0.8583\n",
      "Epoch 30: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 741ms/step - loss: 0.3457 - acc: 0.8583 - val_loss: 0.4606 - val_acc: 0.8246\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3236 - acc: 0.8765\n",
      "Epoch 31: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 761ms/step - loss: 0.3236 - acc: 0.8765 - val_loss: 0.4610 - val_acc: 0.8246\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3204 - acc: 0.8664\n",
      "Epoch 32: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 0.3204 - acc: 0.8664 - val_loss: 0.4643 - val_acc: 0.8070\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3123 - acc: 0.8684\n",
      "Epoch 33: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.3123 - acc: 0.8684 - val_loss: 0.4718 - val_acc: 0.8070\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3058 - acc: 0.8745\n",
      "Epoch 34: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 754ms/step - loss: 0.3058 - acc: 0.8745 - val_loss: 0.4826 - val_acc: 0.7895\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2948 - acc: 0.8725\n",
      "Epoch 35: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 745ms/step - loss: 0.2948 - acc: 0.8725 - val_loss: 0.4903 - val_acc: 0.7895\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2863 - acc: 0.8725\n",
      "Epoch 36: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 0.2863 - acc: 0.8725 - val_loss: 0.4915 - val_acc: 0.8070\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2821 - acc: 0.8765\n",
      "Epoch 37: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 749ms/step - loss: 0.2821 - acc: 0.8765 - val_loss: 0.4886 - val_acc: 0.8070\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2664 - acc: 0.8846\n",
      "Epoch 38: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.2664 - acc: 0.8846 - val_loss: 0.4850 - val_acc: 0.8070\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2604 - acc: 0.9028\n",
      "Epoch 39: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 719ms/step - loss: 0.2604 - acc: 0.9028 - val_loss: 0.4846 - val_acc: 0.8070\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2550 - acc: 0.8887\n",
      "Epoch 40: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 728ms/step - loss: 0.2550 - acc: 0.8887 - val_loss: 0.4872 - val_acc: 0.8070\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2436 - acc: 0.8947\n",
      "Epoch 41: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 0.2436 - acc: 0.8947 - val_loss: 0.4936 - val_acc: 0.8070\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2239 - acc: 0.9049\n",
      "Epoch 42: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 0.2239 - acc: 0.9049 - val_loss: 0.5032 - val_acc: 0.8070\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2188 - acc: 0.9028\n",
      "Epoch 43: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 0.2188 - acc: 0.9028 - val_loss: 0.5139 - val_acc: 0.8070\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2130 - acc: 0.9150\n",
      "Epoch 44: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.2130 - acc: 0.9150 - val_loss: 0.5253 - val_acc: 0.7895\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1970 - acc: 0.9211\n",
      "Epoch 45: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 738ms/step - loss: 0.1970 - acc: 0.9211 - val_loss: 0.5332 - val_acc: 0.8070\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1882 - acc: 0.9352\n",
      "Epoch 46: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.1882 - acc: 0.9352 - val_loss: 0.5367 - val_acc: 0.8070\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1806 - acc: 0.9251\n",
      "Epoch 47: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 0.1806 - acc: 0.9251 - val_loss: 0.5349 - val_acc: 0.8070\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1631 - acc: 0.9372\n",
      "Epoch 48: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.1631 - acc: 0.9372 - val_loss: 0.5361 - val_acc: 0.8246\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1654 - acc: 0.9393\n",
      "Epoch 49: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 721ms/step - loss: 0.1654 - acc: 0.9393 - val_loss: 0.5379 - val_acc: 0.8246\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1697 - acc: 0.9474\n",
      "Epoch 50: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 712ms/step - loss: 0.1697 - acc: 0.9474 - val_loss: 0.5413 - val_acc: 0.8246\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1609 - acc: 0.9413\n",
      "Epoch 51: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 0.1609 - acc: 0.9413 - val_loss: 0.5461 - val_acc: 0.7895\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1485 - acc: 0.9555\n",
      "Epoch 52: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 712ms/step - loss: 0.1485 - acc: 0.9555 - val_loss: 0.5541 - val_acc: 0.7544\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1468 - acc: 0.9575\n",
      "Epoch 53: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 705ms/step - loss: 0.1468 - acc: 0.9575 - val_loss: 0.5582 - val_acc: 0.7544\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1350 - acc: 0.9595\n",
      "Epoch 54: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.1350 - acc: 0.9595 - val_loss: 0.5561 - val_acc: 0.7544\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1279 - acc: 0.9514\n",
      "Epoch 55: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 728ms/step - loss: 0.1279 - acc: 0.9514 - val_loss: 0.5524 - val_acc: 0.7544\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1021 - acc: 0.9696\n",
      "Epoch 56: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 0.1021 - acc: 0.9696 - val_loss: 0.5511 - val_acc: 0.7895\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1224 - acc: 0.9696\n",
      "Epoch 57: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 721ms/step - loss: 0.1224 - acc: 0.9696 - val_loss: 0.5493 - val_acc: 0.7895\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1044 - acc: 0.9636\n",
      "Epoch 58: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.1044 - acc: 0.9636 - val_loss: 0.5485 - val_acc: 0.7895\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0939 - acc: 0.9696\n",
      "Epoch 59: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 739ms/step - loss: 0.0939 - acc: 0.9696 - val_loss: 0.5520 - val_acc: 0.7895\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1021 - acc: 0.9696\n",
      "Epoch 60: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 735ms/step - loss: 0.1021 - acc: 0.9696 - val_loss: 0.5531 - val_acc: 0.7895\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0927 - acc: 0.9737\n",
      "Epoch 61: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 739ms/step - loss: 0.0927 - acc: 0.9737 - val_loss: 0.5489 - val_acc: 0.8070\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0860 - acc: 0.9798\n",
      "Epoch 62: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 745ms/step - loss: 0.0860 - acc: 0.9798 - val_loss: 0.5454 - val_acc: 0.8070\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0860 - acc: 0.9737\n",
      "Epoch 63: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 742ms/step - loss: 0.0860 - acc: 0.9737 - val_loss: 0.5395 - val_acc: 0.8070\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0862 - acc: 0.9737\n",
      "Epoch 64: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 737ms/step - loss: 0.0862 - acc: 0.9737 - val_loss: 0.5318 - val_acc: 0.8070\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0646 - acc: 0.9858\n",
      "Epoch 65: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.0646 - acc: 0.9858 - val_loss: 0.5236 - val_acc: 0.8246\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0702 - acc: 0.9838\n",
      "Epoch 66: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 0.0702 - acc: 0.9838 - val_loss: 0.5167 - val_acc: 0.8246\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0724 - acc: 0.9838\n",
      "Epoch 67: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 0.0724 - acc: 0.9838 - val_loss: 0.5106 - val_acc: 0.8246\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0655 - acc: 0.9818\n",
      "Epoch 68: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 743ms/step - loss: 0.0655 - acc: 0.9818 - val_loss: 0.5060 - val_acc: 0.8070\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0615 - acc: 0.9899\n",
      "Epoch 69: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 709ms/step - loss: 0.0615 - acc: 0.9899 - val_loss: 0.5036 - val_acc: 0.8070\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0589 - acc: 0.9858\n",
      "Epoch 70: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.0589 - acc: 0.9858 - val_loss: 0.5014 - val_acc: 0.7895\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0552 - acc: 0.9858\n",
      "Epoch 71: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.0552 - acc: 0.9858 - val_loss: 0.4968 - val_acc: 0.8070\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0532 - acc: 0.9899\n",
      "Epoch 72: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.0532 - acc: 0.9899 - val_loss: 0.4894 - val_acc: 0.8070\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0430 - acc: 0.9919\n",
      "Epoch 73: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 755ms/step - loss: 0.0430 - acc: 0.9919 - val_loss: 0.4850 - val_acc: 0.8246\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0382 - acc: 0.9939\n",
      "Epoch 74: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 766ms/step - loss: 0.0382 - acc: 0.9939 - val_loss: 0.4813 - val_acc: 0.8246\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0373 - acc: 0.9899\n",
      "Epoch 75: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 743ms/step - loss: 0.0373 - acc: 0.9899 - val_loss: 0.4784 - val_acc: 0.8246\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0365 - acc: 0.9919\n",
      "Epoch 76: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 702ms/step - loss: 0.0365 - acc: 0.9919 - val_loss: 0.4742 - val_acc: 0.8246\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0373 - acc: 0.9879\n",
      "Epoch 77: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 736ms/step - loss: 0.0373 - acc: 0.9879 - val_loss: 0.4732 - val_acc: 0.8246\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0396 - acc: 0.9919\n",
      "Epoch 78: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 740ms/step - loss: 0.0396 - acc: 0.9919 - val_loss: 0.4777 - val_acc: 0.8246\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0314 - acc: 0.9939\n",
      "Epoch 79: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.0314 - acc: 0.9939 - val_loss: 0.4818 - val_acc: 0.8246\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0302 - acc: 0.9939\n",
      "Epoch 80: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.0302 - acc: 0.9939 - val_loss: 0.4815 - val_acc: 0.8246\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0314 - acc: 0.9899\n",
      "Epoch 81: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 712ms/step - loss: 0.0314 - acc: 0.9899 - val_loss: 0.4752 - val_acc: 0.8246\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0348 - acc: 0.9879\n",
      "Epoch 82: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.0348 - acc: 0.9879 - val_loss: 0.4670 - val_acc: 0.8246\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0255 - acc: 0.9939\n",
      "Epoch 83: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 734ms/step - loss: 0.0255 - acc: 0.9939 - val_loss: 0.4620 - val_acc: 0.8246\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0198 - acc: 0.9980\n",
      "Epoch 84: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 0.0198 - acc: 0.9980 - val_loss: 0.4598 - val_acc: 0.8421\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0325 - acc: 0.9879\n",
      "Epoch 85: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 0.0325 - acc: 0.9879 - val_loss: 0.4614 - val_acc: 0.8421\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0200 - acc: 0.9939\n",
      "Epoch 86: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 739ms/step - loss: 0.0200 - acc: 0.9939 - val_loss: 0.4637 - val_acc: 0.8246\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0231 - acc: 0.9960\n",
      "Epoch 87: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 739ms/step - loss: 0.0231 - acc: 0.9960 - val_loss: 0.4656 - val_acc: 0.8246\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0211 - acc: 0.9939\n",
      "Epoch 88: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 730ms/step - loss: 0.0211 - acc: 0.9939 - val_loss: 0.4660 - val_acc: 0.8246\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0155 - acc: 0.9980\n",
      "Epoch 89: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.0155 - acc: 0.9980 - val_loss: 0.4662 - val_acc: 0.8246\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0182 - acc: 0.9960\n",
      "Epoch 90: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 0.0182 - acc: 0.9960 - val_loss: 0.4664 - val_acc: 0.8246\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0146 - acc: 0.9980\n",
      "Epoch 91: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 753ms/step - loss: 0.0146 - acc: 0.9980 - val_loss: 0.4676 - val_acc: 0.8246\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0180 - acc: 0.9980\n",
      "Epoch 92: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 736ms/step - loss: 0.0180 - acc: 0.9980 - val_loss: 0.4686 - val_acc: 0.8246\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0231 - acc: 0.9939\n",
      "Epoch 93: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 836ms/step - loss: 0.0231 - acc: 0.9939 - val_loss: 0.4662 - val_acc: 0.8246\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0157 - acc: 0.9960\n",
      "Epoch 94: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.0157 - acc: 0.9960 - val_loss: 0.4657 - val_acc: 0.8246\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0124 - acc: 0.9980\n",
      "Epoch 95: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 707ms/step - loss: 0.0124 - acc: 0.9980 - val_loss: 0.4650 - val_acc: 0.8246\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0144 - acc: 0.9960\n",
      "Epoch 96: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0144 - acc: 0.9960 - val_loss: 0.4628 - val_acc: 0.8246\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0167 - acc: 0.9939\n",
      "Epoch 97: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 751ms/step - loss: 0.0167 - acc: 0.9939 - val_loss: 0.4629 - val_acc: 0.8246\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0139 - acc: 0.9960\n",
      "Epoch 98: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.0139 - acc: 0.9960 - val_loss: 0.4630 - val_acc: 0.8246\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0147 - acc: 0.9960\n",
      "Epoch 99: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 0.0147 - acc: 0.9960 - val_loss: 0.4639 - val_acc: 0.8421\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0126 - acc: 0.9980\n",
      "Epoch 100: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 0.0126 - acc: 0.9980 - val_loss: 0.4651 - val_acc: 0.8421\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0108 - acc: 0.9980\n",
      "Epoch 101: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 740ms/step - loss: 0.0108 - acc: 0.9980 - val_loss: 0.4662 - val_acc: 0.8421\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0115 - acc: 0.9980\n",
      "Epoch 102: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 738ms/step - loss: 0.0115 - acc: 0.9980 - val_loss: 0.4678 - val_acc: 0.8421\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0149 - acc: 0.9939\n",
      "Epoch 103: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 0.0149 - acc: 0.9939 - val_loss: 0.4695 - val_acc: 0.8421\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - acc: 0.9980\n",
      "Epoch 104: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.0082 - acc: 0.9980 - val_loss: 0.4705 - val_acc: 0.8421\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0100 - acc: 0.9980\n",
      "Epoch 105: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.0100 - acc: 0.9980 - val_loss: 0.4710 - val_acc: 0.8421\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - acc: 0.9980\n",
      "Epoch 106: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 741ms/step - loss: 0.0076 - acc: 0.9980 - val_loss: 0.4715 - val_acc: 0.8421\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - acc: 0.9980\n",
      "Epoch 107: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.0090 - acc: 0.9980 - val_loss: 0.4715 - val_acc: 0.8421\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0104 - acc: 0.9960\n",
      "Epoch 108: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 713ms/step - loss: 0.0104 - acc: 0.9960 - val_loss: 0.4708 - val_acc: 0.8421\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - acc: 0.9980\n",
      "Epoch 109: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 728ms/step - loss: 0.0105 - acc: 0.9980 - val_loss: 0.4700 - val_acc: 0.8246\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0143 - acc: 0.9980\n",
      "Epoch 110: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 740ms/step - loss: 0.0143 - acc: 0.9980 - val_loss: 0.4679 - val_acc: 0.8246\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0113 - acc: 0.9939\n",
      "Epoch 111: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.0113 - acc: 0.9939 - val_loss: 0.4663 - val_acc: 0.8246\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - acc: 0.9960\n",
      "Epoch 112: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 743ms/step - loss: 0.0093 - acc: 0.9960 - val_loss: 0.4647 - val_acc: 0.8246\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 113: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4639 - val_acc: 0.8246\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - acc: 0.9960\n",
      "Epoch 114: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 750ms/step - loss: 0.0099 - acc: 0.9960 - val_loss: 0.4622 - val_acc: 0.8246\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0118 - acc: 0.9960\n",
      "Epoch 115: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 744ms/step - loss: 0.0118 - acc: 0.9960 - val_loss: 0.4611 - val_acc: 0.8246\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 116: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 754ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4603 - val_acc: 0.8246\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - acc: 0.9980\n",
      "Epoch 117: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 731ms/step - loss: 0.0061 - acc: 0.9980 - val_loss: 0.4597 - val_acc: 0.8246\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - acc: 0.9980\n",
      "Epoch 118: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 747ms/step - loss: 0.0073 - acc: 0.9980 - val_loss: 0.4584 - val_acc: 0.8246\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0107 - acc: 0.9980\n",
      "Epoch 119: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 827ms/step - loss: 0.0107 - acc: 0.9980 - val_loss: 0.4572 - val_acc: 0.8246\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0084 - acc: 0.9980\n",
      "Epoch 120: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 751ms/step - loss: 0.0084 - acc: 0.9980 - val_loss: 0.4555 - val_acc: 0.8246\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 121: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 743ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.4536 - val_acc: 0.8246\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - acc: 0.9960\n",
      "Epoch 122: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.0070 - acc: 0.9960 - val_loss: 0.4520 - val_acc: 0.8246\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - acc: 0.9980\n",
      "Epoch 123: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 734ms/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.4513 - val_acc: 0.8246\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - acc: 0.9980\n",
      "Epoch 124: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 0.0062 - acc: 0.9980 - val_loss: 0.4516 - val_acc: 0.8246\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - acc: 0.9980\n",
      "Epoch 125: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 761ms/step - loss: 0.0102 - acc: 0.9980 - val_loss: 0.4541 - val_acc: 0.8246\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - acc: 0.9980\n",
      "Epoch 126: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.0068 - acc: 0.9980 - val_loss: 0.4561 - val_acc: 0.8246\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 127: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 735ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.4565 - val_acc: 0.8246\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - acc: 0.9980\n",
      "Epoch 128: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 751ms/step - loss: 0.0067 - acc: 0.9980 - val_loss: 0.4571 - val_acc: 0.8246\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0091 - acc: 0.9960\n",
      "Epoch 129: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 0.0091 - acc: 0.9960 - val_loss: 0.4551 - val_acc: 0.8246\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0115 - acc: 0.9980\n",
      "Epoch 130: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 902ms/step - loss: 0.0115 - acc: 0.9980 - val_loss: 0.4487 - val_acc: 0.8421\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - acc: 0.9980\n",
      "Epoch 131: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.4431 - val_acc: 0.8421\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - acc: 0.9960\n",
      "Epoch 132: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 920ms/step - loss: 0.0086 - acc: 0.9960 - val_loss: 0.4390 - val_acc: 0.8421\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 133: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 984ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.4353 - val_acc: 0.8421\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - acc: 0.9980\n",
      "Epoch 134: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0079 - acc: 0.9980 - val_loss: 0.4321 - val_acc: 0.8421\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - acc: 0.9980\n",
      "Epoch 135: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 940ms/step - loss: 0.0049 - acc: 0.9980 - val_loss: 0.4296 - val_acc: 0.8421\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - acc: 0.9980\n",
      "Epoch 136: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 0.0073 - acc: 0.9980 - val_loss: 0.4285 - val_acc: 0.8421\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - acc: 0.9960\n",
      "Epoch 137: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.0081 - acc: 0.9960 - val_loss: 0.4287 - val_acc: 0.8421\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0084 - acc: 0.9980\n",
      "Epoch 138: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.0084 - acc: 0.9980 - val_loss: 0.4283 - val_acc: 0.8596\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0111 - acc: 0.9960\n",
      "Epoch 139: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 0.0111 - acc: 0.9960 - val_loss: 0.4262 - val_acc: 0.8596\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - acc: 0.9980\n",
      "Epoch 140: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 740ms/step - loss: 0.0047 - acc: 0.9980 - val_loss: 0.4238 - val_acc: 0.8596\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - acc: 0.9980\n",
      "Epoch 141: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 829ms/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.4197 - val_acc: 0.8596\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 142: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.4160 - val_acc: 0.8421\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - acc: 0.9980\n",
      "Epoch 143: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 0.0052 - acc: 0.9980 - val_loss: 0.4122 - val_acc: 0.8421\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - acc: 0.9980\n",
      "Epoch 144: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.4098 - val_acc: 0.8421\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 145: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.4085 - val_acc: 0.8421\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 146: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 910ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.4061 - val_acc: 0.8421\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 147: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.4041 - val_acc: 0.8421\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 148: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.4024 - val_acc: 0.8421\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - acc: 0.9980\n",
      "Epoch 149: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.0073 - acc: 0.9980 - val_loss: 0.4022 - val_acc: 0.8421\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - acc: 0.9980\n",
      "Epoch 150: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 768ms/step - loss: 0.0055 - acc: 0.9980 - val_loss: 0.4039 - val_acc: 0.8421\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - acc: 0.9980\n",
      "Epoch 151: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.0047 - acc: 0.9980 - val_loss: 0.4076 - val_acc: 0.8596\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - acc: 0.9980\n",
      "Epoch 152: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.0055 - acc: 0.9980 - val_loss: 0.4115 - val_acc: 0.8596\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 153: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.4151 - val_acc: 0.8596\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - acc: 0.9980\n",
      "Epoch 154: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 768ms/step - loss: 0.0068 - acc: 0.9980 - val_loss: 0.4178 - val_acc: 0.8596\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 155: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 758ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.4200 - val_acc: 0.8596\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - acc: 0.9960\n",
      "Epoch 156: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 736ms/step - loss: 0.0071 - acc: 0.9960 - val_loss: 0.4191 - val_acc: 0.8596\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - acc: 0.9980\n",
      "Epoch 157: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 722ms/step - loss: 0.0057 - acc: 0.9980 - val_loss: 0.4175 - val_acc: 0.8421\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 158: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.4169 - val_acc: 0.8421\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 159: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.4148 - val_acc: 0.8421\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 160: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.4127 - val_acc: 0.8421\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - acc: 0.9980\n",
      "Epoch 161: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.0048 - acc: 0.9980 - val_loss: 0.4102 - val_acc: 0.8421\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 162: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.4068 - val_acc: 0.8596\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 163: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 755ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.4047 - val_acc: 0.8596\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - acc: 0.9980\n",
      "Epoch 164: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.4035 - val_acc: 0.8596\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 165: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 892ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.4039 - val_acc: 0.8596\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 166: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.4045 - val_acc: 0.8596\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 167: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 807ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.4048 - val_acc: 0.8596\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 168: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.4046 - val_acc: 0.8421\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 169: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.4045 - val_acc: 0.8421\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 170: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.4042 - val_acc: 0.8421\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 171: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 803ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.4042 - val_acc: 0.8421\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 172: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.4042 - val_acc: 0.8421\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 173: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.4040 - val_acc: 0.8421\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 174: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 871ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.4041 - val_acc: 0.8421\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 175: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.4044 - val_acc: 0.8421\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 176: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 757ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.4053 - val_acc: 0.8421\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 177: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.4061 - val_acc: 0.8421\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 178: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.4067 - val_acc: 0.8421\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9171e-04 - acc: 1.0000\n",
      "Epoch 179: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 9.9171e-04 - acc: 1.0000 - val_loss: 0.4074 - val_acc: 0.8421\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 180: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 743ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.4080 - val_acc: 0.8421\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 181: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.4086 - val_acc: 0.8421\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 182: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.4094 - val_acc: 0.8596\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - acc: 0.9980\n",
      "Epoch 183: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 901ms/step - loss: 0.0044 - acc: 0.9980 - val_loss: 0.4127 - val_acc: 0.8421\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - acc: 0.9980\n",
      "Epoch 184: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0048 - acc: 0.9980 - val_loss: 0.4218 - val_acc: 0.8421\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0033 - acc: 0.9980\n",
      "Epoch 185: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.0033 - acc: 0.9980 - val_loss: 0.4328 - val_acc: 0.8421\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 186: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.4430 - val_acc: 0.8421\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 187: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.4510 - val_acc: 0.8421\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 188: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.4575 - val_acc: 0.8421\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 189: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.4629 - val_acc: 0.8421\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 190: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.4667 - val_acc: 0.8421\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 191: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.4682 - val_acc: 0.8421\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - acc: 0.9980\n",
      "Epoch 192: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 766ms/step - loss: 0.0038 - acc: 0.9980 - val_loss: 0.4645 - val_acc: 0.8421\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 193: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.4613 - val_acc: 0.8421\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.7062e-04 - acc: 1.0000\n",
      "Epoch 194: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 778ms/step - loss: 9.7062e-04 - acc: 1.0000 - val_loss: 0.4576 - val_acc: 0.8421\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - acc: 0.9980\n",
      "Epoch 195: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.0046 - acc: 0.9980 - val_loss: 0.4504 - val_acc: 0.8421\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 196: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 747ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.4439 - val_acc: 0.8421\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 197: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 755ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.4383 - val_acc: 0.8421\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - acc: 0.9980\n",
      "Epoch 198: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 0.0030 - acc: 0.9980 - val_loss: 0.4319 - val_acc: 0.8421\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 199: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 829ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.4266 - val_acc: 0.8421\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 200: val_acc did not improve from 0.85965\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.4215 - val_acc: 0.8421\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(x_train, np.array(y_train), batch_size=256, epochs=200,\n",
    "                    validation_split=0.1, verbose=1, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('bilstmcrf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([141,  64, 164,  35,  52, 139,  34, 189, 189, 189, 189, 189, 189,\n",
       "       189, 189, 189, 189, 189, 189])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "[[[1.09865526e-02 2.01196573e-03 9.29741740e-01 5.72597906e-02]\n",
      "  [1.35992721e-01 1.26652303e-04 7.95209408e-02 7.84359634e-01]\n",
      "  [1.79716170e-01 7.69876078e-06 1.48920089e-01 6.71356082e-01]\n",
      "  [2.03707433e-08 1.42172052e-10 6.26801295e-07 9.99999404e-01]\n",
      "  [1.11219242e-05 1.98743577e-09 9.99963880e-01 2.50016474e-05]\n",
      "  [9.94894922e-01 1.29859060e-07 1.34750037e-04 4.97018034e-03]\n",
      "  [9.99513507e-01 1.79517681e-08 1.29280306e-04 3.57214536e-04]\n",
      "  [9.94127274e-01 3.00112504e-08 4.06301479e-05 5.83199598e-03]\n",
      "  [2.42056927e-07 5.03081223e-11 1.36549785e-08 9.99999762e-01]\n",
      "  [2.35419628e-10 2.77804841e-12 4.56723626e-07 9.99999523e-01]\n",
      "  [1.78725836e-11 4.51562100e-13 4.06795664e-08 1.00000000e+00]\n",
      "  [1.18065930e-11 2.19476862e-13 1.51463766e-08 1.00000000e+00]\n",
      "  [9.28063182e-12 1.59068654e-13 8.83606699e-09 1.00000000e+00]\n",
      "  [7.67166972e-12 1.40210082e-13 6.45302389e-09 1.00000000e+00]\n",
      "  [7.09521634e-12 1.42344198e-13 5.29465449e-09 1.00000000e+00]\n",
      "  [6.62959661e-12 1.54843599e-13 4.34221681e-09 1.00000000e+00]\n",
      "  [5.58763365e-12 1.77627295e-13 3.58410057e-09 1.00000000e+00]\n",
      "  [4.93185050e-12 2.55428355e-13 4.00523836e-09 1.00000000e+00]\n",
      "  [9.34017533e-12 7.64645183e-13 1.27324080e-08 1.00000000e+00]]]\n",
      "[2 0 0 3 2 0 0 1 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Word            Tag             Predicted\n",
      "Hirap           B-SYMPTOM       B-SYMPTOM\n",
      "sa              I-SYMPTOM       O\n",
      "pag-utot        I-SYMPTOM       O\n",
      "at              O               O\n",
      "pananakit       B-SYMPTOM       B-SYMPTOM\n",
      "sa              I-SYMPTOM       I-SYMPTOM\n",
      "kanang          I-SYMPTOM       I-SYMPTOM\n",
      "tagiliran       I               I-SYMPTOM\n",
      ".               O               O\n",
      "UNKNOWN         O               O\n",
      "UNKNOWN         O               O\n",
      "UNKNOWN         O               O\n",
      "UNKNOWN         O               O\n",
      "UNKNOWN         O               O\n",
      "UNKNOWN         O               O\n",
      "UNKNOWN         O               O\n",
      "UNKNOWN         O               O\n",
      "UNKNOWN         O               O\n",
      "UNKNOWN         O               O\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "p = model.predict(np.array([x_test[i]]))\n",
    "print(p)\n",
    "p = np.argmax(p, axis=-1)\n",
    "gt = np.argmax(y_test[i], axis=-1)\n",
    "print(gt)\n",
    "print(\"{:15} {:15} {}\".format(\"Word\", \"Tag\", \"Predicted\"))\n",
    "for idx, (w,pred) in enumerate(zip(x_test[i],p[0])):\n",
    "    print(\"{:15} {:15} {}\".format(words[w],idx2tag[gt[idx]],tags[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 2s 80ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test, batch_size=1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "\n",
    "\n",
    "x_labels = pred2label(y_pred)\n",
    "y_labels = pred2label(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 57.1%\n",
      "Recall: 67.6%\n",
      "F1-score: 61.9%\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "print(\"Precision: {:.1%}\".format(precision_score(y_labels, x_labels)))\n",
    "print(\"Recall: {:.1%}\".format(recall_score(y_labels, x_labels)))\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(y_labels, x_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     SYMPTOM       0.57      0.69      0.62        70\n",
      "           _       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.57      0.68      0.62        71\n",
      "   macro avg       0.29      0.34      0.31        71\n",
      "weighted avg       0.56      0.68      0.61        71\n",
      "\n",
      "[[[15  1]\n",
      "  [ 1  2]]\n",
      "\n",
      " [[15  2]\n",
      "  [ 0  2]]\n",
      "\n",
      " [[ 5  0]\n",
      "  [ 2 12]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#print(np.array(y_test))\n",
    "#print(np.round(y_pred))\n",
    "\n",
    "print(classification_report(y_labels, x_labels))\n",
    "print(multilabel_confusion_matrix(y_labels[0], x_labels[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
